{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "INPUT_CSV = 'data_labeled.csv'\n",
    "\n",
    "CSV_COLUMNS = [\n",
    "    'id',\n",
    "    'url',\n",
    "    'title',\n",
    "    'img_url',\n",
    "    'score',\n",
    "    'servings',\n",
    "    'prep_time',\n",
    "    'rating',\n",
    "    'reviews',\n",
    "    'made_it_count',\n",
    "    'calories',\n",
    "    'total_fat',\n",
    "    'saturated_fat',\n",
    "    'cholesterol',\n",
    "    'sodium',\n",
    "    'potassium',\n",
    "    'carbs',\n",
    "    'dietary_fiber',\n",
    "    'protein',\n",
    "    'sugars',\n",
    "    'vitamin_a',\n",
    "    'vitamin_c',\n",
    "    'calcium',\n",
    "    'iron',\n",
    "    'thiamin',\n",
    "    'niacin',\n",
    "    'vitamin_b6',\n",
    "    'magnesium',\n",
    "    'folate',\n",
    "    # Everything above this index is a <contains> relationship\n",
    "]\n",
    "\n",
    "CSV_COLUMN_TYPES = dict({\n",
    "    'id': 'string',\n",
    "    'url': 'string',\n",
    "    'title': 'string',\n",
    "    'img_url': 'string',\n",
    "    'score': 'int32',\n",
    "    'servings': 'int32',\n",
    "    'prep_time': 'int32',\n",
    "    'rating': 'float32',\n",
    "    'reviews': 'int32',\n",
    "    'made_it_count': 'int32',\n",
    "    'calories': 'int32',\n",
    "    'total_fat': 'float32',\n",
    "    'saturated_fat': 'float32',\n",
    "    'cholesterol': 'float32',\n",
    "    'sodium': 'float32',\n",
    "    'potassium': 'float32',\n",
    "    'carbs': 'float32',\n",
    "    'dietary_fiber': 'float32',\n",
    "    'protein': 'float32',\n",
    "    'sugars': 'float32',\n",
    "    'vitamin_a': 'float32',\n",
    "    'vitamin_c': 'float32',\n",
    "    'calcium': 'float32',\n",
    "    'iron': 'float32',\n",
    "    'thiamin': 'float32',\n",
    "    'niacin': 'float32',\n",
    "    'vitamin_b6': 'float32',\n",
    "    'magnesium': 'float32',\n",
    "    'folate': 'float32',\n",
    "    # Everything above this index is a <contains> relationship\n",
    "})\n",
    "\n",
    "def parse_data(data_csv, max_rows=None):\n",
    "    with open(data_csv, 'r') as f:\n",
    "        reader = csv.reader(f, delimiter=',', quoting=csv.QUOTE_ALL)\n",
    "        \n",
    "        col_len = len(CSV_COLUMNS)\n",
    "        row_count = 0\n",
    "        \n",
    "        for row in reader:\n",
    "            row_arr = [col.replace(r'\"', r'\\\"') for col in row]\n",
    "            yield row_arr[:col_len]\n",
    "            row_count += 1\n",
    "            \n",
    "            if max_rows is not None and row_count >= max_rows:\n",
    "                break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "MAX_ROWS = 831\n",
    "df = pd.DataFrame(data=parse_data(INPUT_CSV, max_rows=MAX_ROWS), columns=(CSV_COLUMNS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calories</th>\n",
       "      <th>total_fat</th>\n",
       "      <th>saturated_fat</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>sodium</th>\n",
       "      <th>potassium</th>\n",
       "      <th>carbs</th>\n",
       "      <th>dietary_fiber</th>\n",
       "      <th>protein</th>\n",
       "      <th>sugars</th>\n",
       "      <th>...</th>\n",
       "      <th>iron</th>\n",
       "      <th>thiamin</th>\n",
       "      <th>niacin</th>\n",
       "      <th>vitamin_b6</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>folate</th>\n",
       "      <th>score</th>\n",
       "      <th>cal_protein</th>\n",
       "      <th>cal_fat</th>\n",
       "      <th>cal_carbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500.0</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.053812</td>\n",
       "      <td>0.380776</td>\n",
       "      <td>0.565412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>308.0</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>26.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.109055</td>\n",
       "      <td>0.552093</td>\n",
       "      <td>0.338851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>339.0</td>\n",
       "      <td>12.300000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>56.200001</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.038957</td>\n",
       "      <td>0.317101</td>\n",
       "      <td>0.643942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>275.0</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>29.400000</td>\n",
       "      <td>1.2</td>\n",
       "      <td>11.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.171886</td>\n",
       "      <td>0.399854</td>\n",
       "      <td>0.428259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276.0</td>\n",
       "      <td>15.700000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>31.900000</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.065346</td>\n",
       "      <td>0.491137</td>\n",
       "      <td>0.443518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>351.0</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1590.0</td>\n",
       "      <td>818.0</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>27.100000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.306215</td>\n",
       "      <td>0.518644</td>\n",
       "      <td>0.175141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>153.0</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>1.1</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.545806</td>\n",
       "      <td>0.260645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>935.0</td>\n",
       "      <td>58.200001</td>\n",
       "      <td>21.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>2274.0</td>\n",
       "      <td>822.0</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>4.2</td>\n",
       "      <td>51.099998</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.218797</td>\n",
       "      <td>0.560694</td>\n",
       "      <td>0.220510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>508.0</td>\n",
       "      <td>35.099998</td>\n",
       "      <td>13.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1096.0</td>\n",
       "      <td>997.0</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>5.6</td>\n",
       "      <td>24.600000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.190587</td>\n",
       "      <td>0.611854</td>\n",
       "      <td>0.197560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>407.0</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>6.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>3608.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.700001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.398095</td>\n",
       "      <td>0.489596</td>\n",
       "      <td>0.112309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     calories  total_fat  saturated_fat  cholesterol  sodium  potassium  \\\n",
       "0       500.0  21.700001           16.0          5.0   291.0      368.0   \n",
       "1       308.0  18.900000           10.0         73.0   482.0      214.0   \n",
       "2       339.0  12.300000            2.0          0.0   122.0      117.0   \n",
       "3       275.0  12.200000            7.0         57.0   399.0      185.0   \n",
       "4       276.0  15.700000            8.0         73.0    60.0      120.0   \n",
       "..        ...        ...            ...          ...     ...        ...   \n",
       "823     351.0  20.400000            7.0         46.0  1590.0      818.0   \n",
       "825     153.0   9.400000            5.0         29.0   529.0      222.0   \n",
       "826     935.0  58.200001           21.0        161.0  2274.0      822.0   \n",
       "827     508.0  35.099998           13.0         97.0  1096.0      997.0   \n",
       "830     407.0  21.700001            6.0        121.0  3608.0      446.0   \n",
       "\n",
       "         carbs  dietary_fiber    protein  sugars  ...  iron  thiamin  niacin  \\\n",
       "0    72.500000            2.1   6.900000    61.0  ...   1.0      0.0     2.0   \n",
       "1    26.100000            1.0   8.400000     3.0  ...   5.0      0.0     4.0   \n",
       "2    56.200001            4.1   3.400000    35.0  ...   1.0      0.0     2.0   \n",
       "3    29.400000            1.2  11.800000     1.0  ...   2.0      0.0     5.0   \n",
       "4    31.900000            1.9   4.700000    25.0  ...   0.0      0.0     1.0   \n",
       "..         ...            ...        ...     ...  ...   ...      ...     ...   \n",
       "823  15.500000            2.5  27.100000     8.0  ...   3.0      0.0     8.0   \n",
       "825  10.100000            1.1   7.500000     3.0  ...   1.0      0.0     2.0   \n",
       "826  51.500000            4.2  51.099998     6.0  ...   9.0      2.0    23.0   \n",
       "827  25.500000            5.6  24.600000    10.0  ...   4.0      0.0    10.0   \n",
       "830  11.200000            2.0  39.700001     0.0  ...   6.0      0.0    12.0   \n",
       "\n",
       "     vitamin_b6  magnesium  folate  score  cal_protein   cal_fat  cal_carbs  \n",
       "0           0.0       31.0    14.0   43.0     0.053812  0.380776   0.565412  \n",
       "1           0.0       17.0    54.0   33.0     0.109055  0.552093   0.338851  \n",
       "2           0.0       19.0    38.0   36.0     0.038957  0.317101   0.643942  \n",
       "3           0.0       29.0    95.0   41.0     0.171886  0.399854   0.428259  \n",
       "4           0.0        4.0     7.0   18.0     0.065346  0.491137   0.443518  \n",
       "..          ...        ...     ...    ...          ...       ...        ...  \n",
       "823         1.0       32.0    32.0   45.0     0.306215  0.518644   0.175141  \n",
       "825         0.0       19.0    25.0   38.0     0.193548  0.545806   0.260645  \n",
       "826         1.0       92.0   197.0   54.0     0.218797  0.560694   0.220510  \n",
       "827         0.0       30.0    20.0   52.0     0.190587  0.611854   0.197560  \n",
       "830         1.0       41.0    16.0   11.0     0.398095  0.489596   0.112309  \n",
       "\n",
       "[690 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_FEATURES = [\n",
    "    'calories',\n",
    "    'total_fat',\n",
    "    'saturated_fat',\n",
    "    'cholesterol',\n",
    "    'sodium',\n",
    "    'potassium',\n",
    "    'carbs',\n",
    "    'dietary_fiber',\n",
    "    'protein',\n",
    "    'sugars',\n",
    "    'vitamin_a',\n",
    "    'vitamin_c',\n",
    "    'calcium',\n",
    "    'iron',\n",
    "    'thiamin',\n",
    "    'niacin',\n",
    "    'vitamin_b6',\n",
    "    'magnesium',\n",
    "    'folate',\n",
    "]\n",
    "\n",
    "RATE_FEATURES = [\n",
    "    'rating',\n",
    "    'reviews',\n",
    "    'made_it_count',\n",
    "]\n",
    "\n",
    "# Augmented columns?\n",
    "# Calorie percentage from protein\n",
    "# Calorie percentage from fat\n",
    "# Calorie percentage from carbs\n",
    "\n",
    "AUG_FEATURES = [\n",
    "    'cal_protein',\n",
    "    'cal_fat',\n",
    "    'cal_carbs'\n",
    "]\n",
    "\n",
    "def compute_aug_cols(row):\n",
    "    protein_cals = row['protein'] * 4.0\n",
    "    fat_cals = row['total_fat'] * 9.0\n",
    "    carb_cals = row['carbs'] * 4.0\n",
    "    \n",
    "    total_cals = sum([protein_cals, fat_cals, carb_cals])\n",
    "    row['cal_protein'] = protein_cals / total_cals\n",
    "    row['cal_fat'] = fat_cals / total_cals\n",
    "    row['cal_carbs'] = carb_cals / total_cals\n",
    "    \n",
    "    return row\n",
    "\n",
    "\n",
    "FEATURES = BASE_FEATURES + AUG_FEATURES\n",
    "\n",
    "DF_COLUMNS = BASE_FEATURES + ['score']\n",
    "df = df[DF_COLUMNS]\n",
    "\n",
    "type_dict = {col:CSV_COLUMN_TYPES[col] for col in DF_COLUMNS}\n",
    "df = df.astype(type_dict)\n",
    "\n",
    "df = df[df['score'] >= 0]\n",
    "\n",
    "df = df.apply(compute_aug_cols, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(690, 22) (690,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = df[FEATURES].to_numpy()\n",
    "y = df['score'].to_numpy()\n",
    "\n",
    "# normalize features\n",
    "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "\n",
    "# normalize labels\n",
    "mean_y = np.mean(y)\n",
    "std_y = np.std(y)\n",
    "y = (y - np.mean(y)) / np.std(y)\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(414, 22) (138, 22) (138, 22)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_val_test_split(data, train_frac, val_frac, test_frac):\n",
    "    assert(train_frac + val_frac + test_frac == 1)\n",
    "    M = data.shape[0]\n",
    "    np.random.seed(628)\n",
    "    np.random.shuffle(data)\n",
    "    return np.split(data, [int(train_frac*M), int((train_frac+val_frac)*M)])\n",
    "\n",
    "# We use a 3:1:1 split for test train and validation\n",
    "X_train, X_val, X_test = train_val_test_split(X, 0.6, 0.2, 0.2)\n",
    "y_train, y_val, y_test = train_val_test_split(y, 0.6, 0.2, 0.2)\n",
    "\n",
    "X_label = np.concatenate((X_train, X_val), axis=0)\n",
    "y_label = np.concatenate((y_train, y_val), axis=0)\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The risk is the average absolute difference\n",
    "# between the predicted and true nutritional score\n",
    "def risk(model, X_, y_):\n",
    "    M_1 = 1.0 / X_.shape[0]\n",
    "    y_hat = model.predict(X_)\n",
    "    abs_error = np.abs(y_hat - y_) * std_y\n",
    "    return M_1 * np.sum(abs_error), np.std(abs_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform kfold analysis on the data. \n",
    "# Returns a list of validation scores for each fold in the data\n",
    "def kfold_analysis(model, X_, y_, cv=5):\n",
    "    return cross_val_score(model, X_, y_, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the data samples with the largest absolute error\n",
    "# We are doing this because the data was manually labeled and may contain errors\n",
    "def outlier_analysis(model, X_, y_):\n",
    "    # We will only analyze data we \n",
    "    model.fit(X_, y_)\n",
    "    y_hat = model.predict(X_)\n",
    "    abs_error = np.abs(y_hat - y_)\n",
    "    # abs_error, y, calories\n",
    "    zipped = list(zip(abs_error, y_, X_[:, FEATURES.index('calories')]))\n",
    "    return sorted(zipped, key=lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dicts(*dicts):\n",
    "    res = dicts[0].copy()\n",
    "    for d in dicts[1:]:\n",
    "        res.update(d)\n",
    "    return res\n",
    "\n",
    "def index_divide(l, i):\n",
    "    for e in l[:i]:\n",
    "        yield e\n",
    "    for e in l[i+1:]:\n",
    "        yield e\n",
    "\n",
    "def k_hold_split(split, i):\n",
    "    train = np.concatenate(tuple(index_divide(split, i)), axis=0)\n",
    "    val = split[i]\n",
    "    return train, val\n",
    "\n",
    "def k_hold_validation(model, D_split, y_split, k):\n",
    "    \"\"\"Returns the risk of a model based on k-hold validation\"\"\"\n",
    "    K_1 = 1.0 / k\n",
    "    acc_risk = 0\n",
    "    \n",
    "    for i in range(k):\n",
    "        D_train, D_val = k_hold_split(D_split, i)\n",
    "        y_train, y_val = k_hold_split(y_split, i)\n",
    "        \n",
    "        model.fit(D_train, y_train)\n",
    "        acc_risk += risk(model, D_val, y_val)[0]\n",
    "    \n",
    "    # Return the average risk\n",
    "    return K_1 * acc_risk\n",
    "        \n",
    "# Train the model using coordinate descent with k-hold validation\n",
    "# If verbose is True, then everytime the algorithm finds better hyperparameters the risk \n",
    "# and parameters will be printed to the console.\n",
    "# Returns the best hyperparameters and risk\n",
    "def fit_coordinate_descent(model_type, _X_label, _y_label, k=5, parameters=dict(), verbose=True):\n",
    "    # Split the data into k parts\n",
    "    D_split = np.array_split(_X_label, k)\n",
    "    y_split = np.array_split(_y_label, k)\n",
    "    \n",
    "    var_params = []\n",
    "    common_params = dict()\n",
    "    for p, v in parameters.items():\n",
    "        if type(v) is list:\n",
    "            var_params.append(p)\n",
    "        else:\n",
    "            common_params[p] = v\n",
    "    \n",
    "    # Train with default hyperparameters\n",
    "    model = model_type(**common_params)\n",
    "    best_params = common_params # default\n",
    "    best_risk = k_hold_validation(model, D_split, y_split, k)\n",
    "    \n",
    "    if verbose:\n",
    "        print(best_risk, 'default')\n",
    "\n",
    "    fixed_params = { p: parameters[p][0] for p in var_params }\n",
    "    \n",
    "    # We try and fit each parameter one at a time\n",
    "    for p_fit in var_params:\n",
    "        for v in parameters[p_fit]:\n",
    "            fitting_param = { p_fit: v }\n",
    "            params = merge_dicts(common_params, fixed_params, fitting_param)\n",
    "            model = model_type(**params)\n",
    "            \n",
    "            # Run a full k-hold validation to test the parameter combination\n",
    "            iter_risk = k_hold_validation(model, D_split, y_split, k)\n",
    "            \n",
    "            if iter_risk < best_risk:\n",
    "                # If the hyperparameters are better, save it to the fixed parameters list\n",
    "                fixed_params[p_fit] = v\n",
    "                best_risk = iter_risk\n",
    "                best_params = params\n",
    "                \n",
    "                if verbose:\n",
    "                    print(iter_risk, params)\n",
    "    \n",
    "    return best_params, best_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2.0017854349123425, -1.9938447464282343, -0.6864355850846982),\n",
       " (1.6673873072662124, -1.733945083633909, -0.9544029687482163),\n",
       " (1.6564258381101458, -1.785925016192774, 0.5440268909212526),\n",
       " (1.6277812107628649, 1.6967304652511852, -0.9325280802858883),\n",
       " (1.566320958550599, 2.6323692513107564, -1.4684628476129247),\n",
       " (1.522436893616936, -1.2141457580452584, -1.3919007379947765),\n",
       " (1.5065532673518436, -1.733945083633909, 0.3252780062979725),\n",
       " (1.4983944701799077, -0.6423664998977426, 1.079961658248289),\n",
       " (1.4640081630306612, 2.5803893187518914, -1.0637774110598563),\n",
       " (1.4555627343137114, -1.058205960368663, 2.8627650679280223),\n",
       " (1.3775717257671358, -1.5260253533984487, -1.2442452408740625),\n",
       " (1.3713121957785013, -1.1101858929275283, -1.2223703524117344),\n",
       " (1.36799894594033, -0.2785069719856872, 0.6260577226549827),\n",
       " (1.3652452767981518, -0.9022661626920679, -0.47315542257700005),\n",
       " (1.354391625712176, 1.6447505326923202, -1.2387765187584805),\n",
       " (1.3531114617519056, 1.6447505326923202, -0.5497175321951481),\n",
       " (1.3529810717237576, -1.1621658254863934, -0.7903413052807562),\n",
       " (1.3500806298941332, -0.9542460952509331, -0.19971931679789987),\n",
       " (1.3162570320500477, -1.2661256906041234, -0.8997157475923963),\n",
       " (1.286796474381502, -1.1621658254863934, 0.5604330572679986)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Get the top 20 bad samples. Data should be unnormalized before running so that samples can be identified\n",
    "outlier_analysis(LinearRegression(), X, y)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64378339 0.64978618 0.62663227 0.5839701  0.60233383]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Run k-fold cross validation analysis. We expect that the validation score for each fold \n",
    "# is roughly equal if the partitions are iid.\n",
    "print(kfold_analysis(LinearRegression(), X_label, y_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Risk (16.816565147378, 10.651524788856511)\n"
     ]
    }
   ],
   "source": [
    "# Implement trivial estimator (guesses mean) to get upper bound on acceptable error\n",
    "class TrivialEstimator:\n",
    "    def __init__(self):\n",
    "        self.mean = 0\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.mean = np.mean(y)\n",
    "    \n",
    "    def predict(self, _):\n",
    "        return self.mean\n",
    "    \n",
    "est = TrivialEstimator()\n",
    "est.fit(X_train, y_train)\n",
    "print('Validation Risk', risk(est, X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.459243994315843 default\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "best_linreg_params, best_linreg_risk = fit_coordinate_descent(LinearRegression, X_label, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.509923859903493 default\n",
      "9.456763772222752 {'random_state': 628, 'max_iter': None, 'alpha': 0.01}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_params = {\n",
    "    'random_state': 628,\n",
    "    'max_iter': [None, 100, 1000],\n",
    "    'alpha': [0.01, 0.3, 1, 3, 10], # Controls strength of l2 regularization\n",
    "}\n",
    "\n",
    "best_ridge_params, best_ridge_risk = fit_coordinate_descent(Ridge, X_label, y_label, parameters=ridge_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.315889703788866 default\n",
      "9.504338282118882 {'random_state': 628, 'max_iter': 10000, 'l1_ratio': 1.0, 'alpha': 0.001}\n",
      "9.490512726244082 {'random_state': 628, 'max_iter': 10000, 'l1_ratio': 0.7, 'alpha': 0.001}\n",
      "9.485070810057264 {'random_state': 628, 'max_iter': 10000, 'l1_ratio': 0.5, 'alpha': 0.001}\n",
      "9.48144124676106 {'random_state': 628, 'max_iter': 10000, 'l1_ratio': 0.3, 'alpha': 0.001}\n",
      "9.478983627737641 {'random_state': 628, 'max_iter': 10000, 'l1_ratio': 0.1, 'alpha': 0.001}\n",
      "9.478222175947286 {'random_state': 628, 'max_iter': 10000, 'l1_ratio': 0.01, 'alpha': 0.001}\n",
      "9.478138604019149 {'random_state': 628, 'max_iter': 10000, 'l1_ratio': 0.001, 'alpha': 0.001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "enet_params = {\n",
    "    'random_state': 628,\n",
    "    'max_iter': 10000,\n",
    "    'l1_ratio': [1.0, 0.7, 0.5, 0.3, 0.1, 0.01, 0.001], # controls weighted portion of l1 regularization. 1.0 means full l_1 regularization\n",
    "    'alpha': [0.001, 0.01, 0.1], # Controls strength of regularization\n",
    "}\n",
    "\n",
    "best_enet_params, best_enet_risk = fit_coordinate_descent(ElasticNet, X_label, y_label, parameters=enet_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.337839937315657 default\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({}, 10.337839937315657)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import TheilSenRegressor\n",
    "\n",
    "fit_coordinate_descent(TheilSenRegressor, X_label, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.217816540046561 default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/overflow/ece493/nutrition-regressor/.venv/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/mnt/overflow/ece493/nutrition-regressor/.venv/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/mnt/overflow/ece493/nutrition-regressor/.venv/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/mnt/overflow/ece493/nutrition-regressor/.venv/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/mnt/overflow/ece493/nutrition-regressor/.venv/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.171270699450522 {'random_state': 628, 'verbose': False, 'max_iter': 1000, 'solver': 'sgd', 'activation': 'relu', 'hidden_layer_sizes': (100,), 'alpha': 0.0001}\n",
      "7.618993571809913 {'random_state': 628, 'verbose': False, 'max_iter': 1000, 'solver': 'sgd', 'activation': 'relu', 'hidden_layer_sizes': (100, 100), 'alpha': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "nn_params = {\n",
    "    'random_state': 628,\n",
    "    'verbose': False,\n",
    "    'max_iter': 1000,\n",
    "    'solver': ['adam', 'lbfgs', 'sgd'], # adam solver, newton's method or stochastic gradient descent\n",
    "    'activation': ['relu', 'identity'],\n",
    "    'hidden_layer_sizes': [(100,), (len(FEATURES),), (len(FEATURES*2),), (100,100), (len(FEATURES*2),len(FEATURES*2))],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "}\n",
    "\n",
    "best_nn_params, best_nn_risk = fit_coordinate_descent(MLPRegressor, X_label, y_label, parameters=nn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 628, 'verbose': False, 'max_iter': 1000, 'solver': 'sgd', 'activation': 'relu', 'hidden_layer_sizes': (100, 100), 'alpha': 0.0001}\n",
      "Test Score:  (7.104656565791909, 6.5444618276223165)\n"
     ]
    }
   ],
   "source": [
    "print(best_nn_params)\n",
    "reg_final = MLPRegressor(**best_nn_params).fit(X_label, y_label)\n",
    "print('Test Score: ', risk(reg_final, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model to a file\n",
    "fname = 'nutriscore.model'\n",
    "pickle.dump(reg_final, open(fname, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
